{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Tokenize_and_StopWords.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pW2fydwXLkQi",
        "outputId": "3e2f3018-11ae-4378-ac72-89ee25d65de9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [1 InRelease 14.2 kB/88.\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [1 InRelease 48.9 kB/88.\r0% [2 InRelease gpgv 1,575 B] [Waiting for headers] [1 InRelease 51.8 kB/88.7 k\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,498 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,734 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,958 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,004 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,272 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,181 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [954 kB]\n",
            "Get:21 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Fetched 13.9 MB in 6s (2,301 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0 from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.3'\n",
        "spark_version = 'spark-3.2.1'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Tokens\").getOrCreate()"
      ],
      "metadata": {
        "id": "ZKeDh6PQMMcP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Tokenizer Library\n",
        "from pyspark.ml.feature import Tokenizer"
      ],
      "metadata": {
        "id": "FWU6-MTKMV7e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample DataFrame\n",
        "dataframe = spark.createDataFrame([\n",
        "                                   (0, \"BCS Link has not been working today\"),\n",
        "                                   (1, \"What am I doing wrong\"),\n",
        "                                   (2, \"Please Update!!\")\n",
        "],[\"id\", \"sentence\"])\n",
        "dataframe.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDiagBNtMavE",
        "outputId": "a5bbd74a-f9c8-4063-eecc-505f2ca03748"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+\n",
            "| id|            sentence|\n",
            "+---+--------------------+\n",
            "|  0|BCS Link has not ...|\n",
            "|  1|What am I doing w...|\n",
            "|  2|     Please Update!!|\n",
            "+---+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize sentences with Spark\n",
        "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
        "tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC7UeXAjM0TA",
        "outputId": "8dc09df3-71df-414a-e904-06d3e8776bd4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tokenizer_d1235fc7a068"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform and show DataFrame\n",
        "tokenized_df = tokenizer.transform(dataframe)\n",
        "tokenized_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvHdl06uNJrP",
        "outputId": "bb98e263-52c1-488a-c55a-90a6d64b38ec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------------------------------+-------------------------------------------+\n",
            "|id |sentence                           |words                                      |\n",
            "+---+-----------------------------------+-------------------------------------------+\n",
            "|0  |BCS Link has not been working today|[bcs, link, has, not, been, working, today]|\n",
            "|1  |What am I doing wrong              |[what, am, i, doing, wrong]                |\n",
            "|2  |Please Update!!                    |[please, update!!]                         |\n",
            "+---+-----------------------------------+-------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we will turn this into a 'user-defined function' (UDF) below \n",
        "# function returns the length of a list\n",
        "def word_list_length(word_list):\n",
        "  return len(word_list)"
      ],
      "metadata": {
        "id": "nCFpkaJzNgkC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the udf function, the col function (to select a column to be passed into the udf), and the type IntegerType that will be used in our udf to define the datatype\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import IntegerType"
      ],
      "metadata": {
        "id": "Si0_sNeANxi8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn our function into a UDF\n",
        "count_tokens = udf(word_list_length, IntegerType())"
      ],
      "metadata": {
        "id": "M9595s-jOLpF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-create our Tokenizer\n",
        "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
        "\n",
        "# Transform DataFrame\n",
        "tokenized_df = tokenizer.transform(dataframe)\n",
        "\n",
        "# Select the needed columns and don't truncate results\n",
        "tokenized_df.withColumn(\"tokens\", count_tokens(col(\"words\"))).show(truncate=False)"
      ],
      "metadata": {
        "id": "Gs6vIwHfOn2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d38ca3dd-1d67-40e0-d04e-b82f6a5c6346"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------------------------------+-------------------------------------------+------+\n",
            "|id |sentence                           |words                                      |tokens|\n",
            "+---+-----------------------------------+-------------------------------------------+------+\n",
            "|0  |BCS Link has not been working today|[bcs, link, has, not, been, working, today]|7     |\n",
            "|1  |What am I doing wrong              |[what, am, i, doing, wrong]                |5     |\n",
            "|2  |Please Update!!                    |[please, update!!]                         |2     |\n",
            "+---+-----------------------------------+-------------------------------------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Stop Words library\n",
        "from pyspark.ml.feature import StopWordsRemover"
      ],
      "metadata": {
        "id": "SMJ1aiNMP3MQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the remover\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")"
      ],
      "metadata": {
        "id": "nerg7AoBRMPf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform and show data\n",
        "remover.transform(tokenized_df).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5Y4o4kFRaNz",
        "outputId": "ca787b4f-5197-44b1-ed0e-45a1eb65bbf9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------------------------------+-------------------------------------------+---------------------------+\n",
            "|id |sentence                           |words                                      |filtered                   |\n",
            "+---+-----------------------------------+-------------------------------------------+---------------------------+\n",
            "|0  |BCS Link has not been working today|[bcs, link, has, not, been, working, today]|[bcs, link, working, today]|\n",
            "|1  |What am I doing wrong              |[what, am, i, doing, wrong]                |[wrong]                    |\n",
            "|2  |Please Update!!                    |[please, update!!]                         |[please, update!!]         |\n",
            "+---+-----------------------------------+-------------------------------------------+---------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OtEbGyeGRkQY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}